{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5791434,"sourceType":"datasetVersion","datasetId":3326190}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# dataset exploration","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport numpy as np\nimport geopandas as gpd\nimport plotly.express as px\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/american-companies-bankruptcy-prediction-dataset/american_bankruptcy.csv')\ndf.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.rename(columns={'X1':'Current assets','X2':'Cost of goods sold','X3':'Depreciation and amortization','X4':'EBITDA','X5':'Inventory','X6':'Net Income','X7':'Total Receivables','X8':'Market value','X9':'Net sales','X10':'Total assets','X11':'Total Long-term debt','X12':'EBIT','X13':'Gross Profit','X14':'Total Current Liabilities','X15':'Retained Earnings','X16':'Total Revenue','X17':'Total Liabilities','X18':'Total Operating Expenses'},inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.describe().T","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.describe(include='object')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.duplicated().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['status_label'].unique()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_numeric=df.copy()\ndf_numeric.drop(columns=['company_name'],inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def binaryclass(row):\n    if row['status_label'] == 'alive':\n        return(1)\n    else:\n        return(0)\ndf_numeric['status_label']=df.apply(binaryclass,axis=1)\ndf_numeric.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(30,30))\ncorr = df_numeric.corr()\n\n\nsns.heatmap(corr, \n            xticklabels=corr.columns,\n            yticklabels=corr.columns,\n            cmap='coolwarm',\n            annot=True,\n            linewidths=.5)\n \nplt.title('Correlation Matrix')\n# plt.xticks(rotation=90)\n# plt.yticks(rotation=0) \n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"xtick_positions = [2000,2005,2008,2010, 2012, 2014, 2016, 2018]\n# xtick_labels = [2'2010', '2012', '2014', '2016', '2018']\n\n# Set xticks with positions and labels\nplt.xticks(xtick_positions)\ndf_numeric.groupby(['year'])['Gross Profit'].mean().plot()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate mean by year for all numeric features\ndf_means = df_numeric.groupby('year').mean()\n\n# Get number of rows and columns for subplots based on feature count\nn_features = len(df_means.columns)\nn_rows = (n_features // 5) + 1  # Assuming 5 features per row (adjust as needed)\nn_cols = min(5, n_features)  # Maximum 5 columns per row\n\n# Create the figure and subplots\nfig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 10))  # Adjust figsize as desired\n\n\n# Loop through features and plot on subplots\nfeature_index = 0\nfor row in range(n_rows):\n  for col in range(n_cols):\n    if feature_index >= n_features:\n      break  # No more features, exit loop\n    feature_name = df_means.columns[feature_index]\n    df_means[feature_name].plot(kind='line', ax=axes[row, col])\n    axes[row, col].set_title(feature_name)\n    feature_index += 1\n\n# Adjust layout (optional)\nplt.tight_layout()\n\n# Show the plot\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## decrease in all revenues in 2009\n* 2007-2008: The housing bubble in the US began to burst, leading to defaults on mortgages and losses for financial institutions. This triggered a domino effect, causing a credit freeze and a decline in overall economic activity.\n* 2008: The crisis reached its peak, with major financial institutions facing collapse and government intervention needed to stabilize the financial system.\n* 2009 and beyond: The recession officially began in December 2007 (according to the National Bureau of Economic Research) and continued through much of 2009. The effects of the crisis, including decreased consumer spending and business investment, were felt throughout this period and even in later years.\n### Therefore, it's very likely that the profit deficits observed for the year 2009 are a consequence of the 2008 financial crisis. The crisis had a significant impact on businesses across various sectors, leading to decreased sales, increased expenses, and ultimately, losses in many cases.\n\n\n","metadata":{}},{"cell_type":"markdown","source":"## The Treasury recently reported that the federal government recorded a total budget deficit of \\\\$1.4 trillion in fiscal year 2009, about \\\\$960 billion more than the deficit incurred in 2008. CBO notes, in its latest Monthly Budget Review, that the federal deficit rose as a share of the nations gross domestic product (GDP) from 3.1 percent in 2008 to 9.9 percent in 2009the highest deficit as a share of GDP since 1945.\n[www.cbo.gov/publication/24992](https://)","metadata":{}},{"cell_type":"code","source":"df.groupby(['company_name'])['Net Income'].mean().sort_values(ascending=False).head().plot(kind='bar')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.groupby(['company_name'])['Total Revenue'].mean().sort_values(ascending=False).head().plot(kind='bar')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_numeric.plot(kind = \"box\" , subplots = True , figsize = (20,20) , layout = (4,5))\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* We have a lot of outliers.\n* Outliers will not be removed, because when I did so, there were no bankrupt companies left in the database. So I preferred to keep all the data, considering that in the outliers there could be important information of 1 (bankruptcy).","metadata":{}},{"cell_type":"code","source":"# Select all numerical features (replace 'numeric_features' with your actual list if needed)\nnumeric_features = [col for col in df.columns if df[col].dtype != object]\n\n# Define number of rows and columns for the subplot grid (adjust based on your number of features)\nn_rows = 4  # Adjust as needed\nn_cols = 5  # Adjust as needed\n\n# Create a figure and subplots using plt.subplots\nfig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 10))\n\n# Iterate through features and create scatter plots on subplots\nfeature_count = 0\nfor i in range(n_rows):\n    for j in range(n_cols):\n        if feature_count >= len(numeric_features):\n            break  # No more features to plot, exit loop\n\n        # Access the current subplot using axes[i, j]\n        ax = axes[i, j]\n\n        # Scatter plot on current subplot\n        ax.scatter(df['year'], df[numeric_features[feature_count]], c=df_numeric['status_label'], cmap='cool', alpha=0.3)\n\n        # Add horizontal line at y=0\n        ax.axhline(0, c='black', ls='--')\n\n        # Feature label and title (optional)\n        ax.set_xlabel('Year')\n        ax.set_ylabel(numeric_features[feature_count] + ' Value')\n        ax.set_title(numeric_features[feature_count] + ' vs. Year')\n\n        feature_count += 1\n\n# Adjust layout to prevent overlapping elements\nplt.tight_layout()\n\n# Colorbar for status_label (optional, position outside subplots)\n# You can adjust the position using fig.colorbar(...,の位置)\nfig.colorbar(label='Status Label', ax=axes.ravel())\n\n# Show the plot\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# preprocessing","metadata":{}},{"cell_type":"code","source":"df2 = df[df.groupby(['company_name'])['status_label'].transform('nunique') > 1]\ndf2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## there are no companies with the same name that changed status\n### i.e alive companies that turned bankrupt or bankrupt companies that started working","metadata":{}},{"cell_type":"code","source":"df['company_name'].value_counts().count()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## number of actual companies","metadata":{}},{"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom yellowbrick.cluster import KElbowVisualizer\nfeatures = ['Net Income', 'Market value', 'Total Revenue']\nX = df[features].values\n\n# Instantiate the clustering model and visualizer\nkm = KMeans(random_state=42)\nvisualizer = KElbowVisualizer(km, k=(2,10))\n \nvisualizer.fit(X)        # Fit the data to the visualizer\nvisualizer.show() ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"kmeans = KMeans(n_clusters = 4, init = 'k-means++', random_state = 42)\ny_kmeans = kmeans.fit_predict(X)\n# Visualising the clusters\nplt.scatter(X[y_kmeans == 0,0 ], X[y_kmeans == 0,1], s = 100, c = 'red', label = 'Cluster 1')\nplt.scatter(X[y_kmeans == 1 ,0], X[y_kmeans == 1,1], s = 100, c = 'blue', label = 'Cluster 2')\nplt.scatter(X[y_kmeans == 2 ,0], X[y_kmeans == 2,1], s = 100, c = 'green', label = 'Cluster 3')\nplt.scatter(X[y_kmeans == 3,0], X[y_kmeans == 3,1], s = 100, c = 'cyan', label = 'Cluster 4')\n# plt.scatter(X[y_kmeans == 4, 0], X[y_kmeans == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5')\n# plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 300, c = 'yellow', label = 'Centroids')\nplt.title('Clusters of customers')\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import plotly.graph_objects as go\nScene = dict(xaxis = dict(title  = 'Net Income -->'),yaxis = dict(title  = 'Market Value--->'),zaxis = dict(title  = 'Total Revenue-->'))\n\nlabels = kmeans.labels_\ntrace = go.Scatter3d(x=X[:, 0], y=X[:, 1], z=X[:, 2], mode='markers',marker=dict(color = labels, size= 10, line=dict(color= 'black',width = 10)))\nlayout = go.Layout(margin=dict(l=0,r=0),scene = Scene,height = 800,width = 800)\ndata = [trace]\nfig = go.Figure(data = data, layout = layout)\nfig.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### tried clustering","metadata":{}},{"cell_type":"code","source":"df_numeric.groupby('status_label').size().plot(kind='pie',\n                                       autopct='%.1f%%',\n                                       fontsize=13,\n                                                labels=['bankrupt','not bankrupt'],\n                                       colors=['skyblue', 'tomato'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n# Resampling the minority class. The strategy can be changed as required.\nsm = SMOTE(sampling_strategy='minority', random_state=42)\n# Fit the model to generate the data.\noversampled_X, oversampled_Y = sm.fit_resample(df_numeric.drop('status_label', axis=1,inplace=False), df_numeric['status_label'])\noversampled = pd.concat([pd.DataFrame(oversampled_Y), pd.DataFrame(oversampled_X)], axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"oversampled.groupby('status_label').size().plot(kind='pie',\n                                       autopct='%.1f%%',\n                                       fontsize=13,\n                                                labels=['bankrupt','not bankrupt'],\n                                       colors=['skyblue', 'tomato'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":" df.status_label.value_counts()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df2=df.groupby('company_name').agg({'status_label': 'first'})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df2.status_label.value_counts()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Filter for failed companies (status_label=0)\nfailed_companies = df[df['status_label'] == 'failed']\n\n# Remove duplicates for alive companies (status_label=1) based on company_name only\nalive_companies = df[df['status_label'] == 'alive'].drop_duplicates(subset='company_name')\n\n# Combine alive and unique failed companies\nall_companies = pd.concat([alive_companies, failed_companies], ignore_index=True)\n\n# Print the resulting DataFrame\nall_companies.status_label.value_counts()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_companies['status_label']=all_companies.apply(binaryclass,axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_companies.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_companies.groupby('status_label').size().plot(kind='pie',\n                                       autopct='%.1f%%',\n                                       fontsize=13,\n                                                labels=['bankrupt','not bankrupt'],\n                                       colors=['skyblue', 'tomato'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.pairplot(data=all_companies,hue='status_label',kind='scatter')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Select all numerical features (replace 'numeric_features' with your actual list if needed)\nnumeric_features = [col for col in all_companies.columns if df[col].dtype != object]\n\n# Define number of rows and columns for the subplot grid (adjust based on your number of features)\nn_rows = 4  # Adjust as needed\nn_cols = 5  # Adjust as needed\n\n# Create a figure and subplots using plt.subplots\nfig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 10))\n\n# Iterate through features and create scatter plots on subplots\nfeature_count = 0\nfor i in range(n_rows):\n    for j in range(n_cols):\n        if feature_count >= len(numeric_features):\n            break  # No more features to plot, exit loop\n\n        # Access the current subplot using axes[i, j]\n        ax = axes[i, j]\n\n        # Scatter plot on current subplot\n        ax.scatter(all_companies['year'], all_companies[numeric_features[feature_count]], c=all_companies['status_label'], cmap='cool', alpha=0.3)\n\n        # Add horizontal line at y=0\n        ax.axhline(0, c='black', ls='--')\n\n        # Feature label and title (optional)\n        ax.set_xlabel('Year')\n        ax.set_ylabel(numeric_features[feature_count] + ' Value')\n        ax.set_title(numeric_features[feature_count] + ' vs. Year')\n\n        feature_count += 1\n\n# Adjust layout to prevent overlapping elements\nplt.tight_layout()\n\n# Colorbar for status_label (optional, position outside subplots)\n# You can adjust the position using fig.colorbar(...,の位置)\nfig.colorbar(label='Status Label', ax=axes.ravel())\n\n# Show the plot\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_companies.drop(columns=['company_name'],inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate mean by year for all numeric features\ndf_means = all_companies.groupby('year').mean()\n\n# Get number of rows and columns for subplots based on feature count\nn_features = len(df_means.columns)\nn_rows = (n_features // 5) + 1  # Assuming 5 features per row (adjust as needed)\nn_cols = min(5, n_features)  # Maximum 5 columns per row\n\n# Create the figure and subplots\nfig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 10))  # Adjust figsize as desired\n\n\n# Loop through features and plot on subplots\nfeature_index = 0\nfor row in range(n_rows):\n  for col in range(n_cols):\n    if feature_index >= n_features:\n      break  # No more features, exit loop\n    feature_name = df_means.columns[feature_index]\n    df_means[feature_name].plot(kind='line', ax=axes[row, col])\n    axes[row, col].set_title(feature_name)\n    feature_index += 1\n\n# Adjust layout (optional)\nplt.tight_layout()\n\n# Show the plot\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(30,30))\ncorr = all_companies.corr()\n\n\nsns.heatmap(corr, \n            xticklabels=corr.columns,\n            yticklabels=corr.columns,\n            cmap='coolwarm',\n            annot=True,\n            linewidths=.5)\n \nplt.title('Correlation Matrix')\n# plt.xticks(rotation=90)\n# plt.yticks(rotation=0) \n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"has_negatives = all_companies.lt(0).any()\n\n# has_negatives is a Series containing True/False for each column\n\n# Print column names with negative values (optional)\nif has_negatives.any():\n  negative_cols = has_negatives[has_negatives].index.tolist()\n  print(\"Columns with negative values:\", negative_cols)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Profitability Ratios:\n\n* Net Profit Margin: (Net Income) / (Revenue) - Measures the percentage of revenue that is converted into profit.\n* Return on Equity (ROE): (Net Income) / (Shareholder Equity) - Measures the return on investment for shareholders.\n* Return on Assets (ROA): (Net Income) / (Total Assets) - Measures the efficiency of using assets to generate profit.\n* Gross Profit Margin: (Gross Profit) / (Net Sales) - Measures the profit remaining after accounting for the cost of goods sold.\n* Return on Sales (ROS): (Net Income) / (Net Sales) - Similar to Net Profit Margin, but expressed as a percentage.\n\n\nLiquidity Ratios:\n\n* Current Ratio: (Current Assets) / (Current Liabilities) - Measures a company's ability to pay off short-term liabilities with its current assets.\n* Quick Ratio: (Current Assets - Inventory) / (Current Liabilities) - A more conservative measure of liquidity that excludes inventory from current assets.\n* Cash Ratio: (Cash and Cash Equivalents) / (Current Liabilities) - The most stringent liquidity measure, indicating a company's ability to pay off short-term liabilities solely with cash.\n\nSolvency Ratios:\n\n* Debt-to-Equity Ratio: (Total Liabilities) / (Shareholder Equity) - Measures a company's financial leverage and its reliance on debt financing.\n* Debt-to-Asset Ratio: (Total Liabilities) / (Total Assets) - Indicates the proportion of a company's assets financed by debt.\n\nActivity Ratios:\n\n* Inventory Turnover: (Cost of Goods Sold) / (Average Inventory) - Measures how efficiently a company is selling its inventory.\n* Receivables Turnover: (Revenue) / (Average Accounts Receivable) - Measures how efficiently a company is collecting payments from customers.\n\n\nAdditional Ratios (if applicable):\n\n* EBITDA Margin: (EBITDA) / (Revenue) - Earnings Before Interest, Taxes, Depreciation, and Amortization margin, a measure of profitability excluding non-cash expenses.\n* Price-to-Earnings Ratio (P/E Ratio): (Stock Price) / (Earnings per Share) - A market valuation metric used to compare companies within the same industry.","metadata":{}},{"cell_type":"code","source":"all_companies.columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_companies['Net Profit Margin']=all_companies['Net Income']/all_companies['Total Revenue']\nall_companies['Gross Profit Margin']=all_companies['Gross Profit']/all_companies['Net sales']\nall_companies['ROA']=all_companies['Net Income']/all_companies['Total assets']\nall_companies['ROS']=all_companies['Net Income']/all_companies['Net sales']\nall_companies['Current Ratio']=all_companies['Current assets']/all_companies['Total Current Liabilities']\nall_companies['Quick Ratio']=(all_companies['Current assets']-all_companies['Inventory'])/all_companies['Total Current Liabilities']\nall_companies['Debt to asset ratio']=all_companies['Total Liabilities']/all_companies['Total assets']\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(30,30))\ncorr = all_companies.corr()\n\n\nsns.heatmap(corr, \n            xticklabels=corr.columns,\n            yticklabels=corr.columns,\n            cmap='coolwarm',\n            annot=True,\n            linewidths=.5)\n \nplt.title('Correlation Matrix')\n# plt.xticks(rotation=90)\n# plt.yticks(rotation=0) \n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_companies.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Select all numerical features (replace 'numeric_features' with your actual list if needed)\nnumeric_features = [col for col in all_companies.columns if all_companies[col].dtype != object]\n\n# Define number of rows and columns for the subplot grid (adjust based on your number of features)\nn_rows = 7  # Adjust as needed\nn_cols = 4  # Adjust as needed\n\n# Create a figure and subplots using plt.subplots\nfig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 20))\n\n# Iterate through features and create scatter plots on subplots\nfeature_count = 0\nfor i in range(n_rows):\n    for j in range(n_cols):\n        if feature_count >= len(numeric_features):\n            break  # No more features to plot, exit loop\n\n        # Access the current subplot using axes[i, j]\n        ax = axes[i, j]\n\n        # Scatter plot on current subplot\n        ax.scatter(all_companies['year'], all_companies[numeric_features[feature_count]], c=all_companies['status_label'], cmap='cool', alpha=0.3)\n\n        # Add horizontal line at y=0\n        ax.axhline(0, c='black', ls='--')\n\n        # Feature label and title (optional)\n        ax.set_xlabel('Year')\n        ax.set_ylabel(numeric_features[feature_count] + ' Value')\n        ax.set_title(numeric_features[feature_count] + ' vs. Year')\n\n        feature_count += 1\n\n# Adjust layout to prevent overlapping elements\nplt.tight_layout()\n\n# Colorbar for status_label (optional, position outside subplots)\n# You can adjust the position using fig.colorbar(...,の位置)\nfig.colorbar(label='Status Label', ax=axes.ravel())\n\n# Show the plot\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_companies.columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# model training and results","metadata":{}},{"cell_type":"code","source":"x = all_companies.drop([\"status_label\"] , axis = 1).values\n# ,'cluster_label','Net sales','Current Ratio','Quick Ratio','Debt to asset ratio','Total Long-term debt','Total Receivables','Market value','Gross Profit'\n#                        ,'EBIT','Total Revenue','Net Profit Margin','Gross Profit Margin','Cost of goods sold'\n# x=X.drop(['status_label'],axis=1).values\ny = all_companies[\"status_label\"].values\nx_train , x_test , y_train ,y_test = train_test_split(x,y , test_size= 0.25 , random_state= 42)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.feature_selection import f_classif\nfeature_names=all_companies.drop(columns=['status_label']).columns\n# Create f_classif object to calculate F-value\nf_value = f_classif(x, y)\n\n# Print the name and F-value of each feature\nfor feature in zip(feature_names, f_value[0]):\n    print(feature)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a bar chart for visualizing the F-values\nplt.figure(figsize=(4,4))\nplt.bar(x=feature_names, height=f_value[0], color='tomato')\nplt.xticks(rotation='vertical')\nplt.ylabel('F-value')\nplt.title('F-value Comparison')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler().fit(x_train)\nx_train_scaled = scaler.transform(x_train)\nx_test_scaled = scaler.transform(x_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfor i in range (1,10,2):\n  neigh = KNeighborsClassifier(n_neighbors=i)\n  neigh.fit(x_train_scaled,y_train)\n  predict = neigh.predict(x_test_scaled)\n  print(\"classification report of k= \", i)\n  print(classification_report(predict,y_test))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\n\n# Fit the model\nnb.fit(x_train, y_train)\n\ny_pred = nb.predict(x_test)\n\ncr = classification_report(y_test, y_pred)\nprint(\"\\n\\nClassification Report\\n\")\nprint(cr)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\nfrom sklearn import metrics\nlinear_clf = SGDClassifier(class_weight='balanced')\n\n# Train the classifier using fit() function\nlinear_clf.fit(x_train_scaled, y_train)\n\ny_test_pred = linear_clf.predict(x_test_scaled)\ncm=metrics.confusion_matrix(y_test,y_test_pred)\ndisp=metrics.ConfusionMatrixDisplay(confusion_matrix=cm)\ndisp.plot()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(classification_report(y_test_pred,y_test))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\ndt=DecisionTreeClassifier(random_state=42,class_weight='balanced',)\nparam_grid = { \n    'max_features': [ 'sqrt', 'log2'],\n    'criterion' :['gini', 'entropy','log_loss']\n}\nCV_dt = GridSearchCV(estimator=dt, param_grid=param_grid, cv= 5)\nCV_dt.fit(x_train, y_train)\nprint(CV_dt.best_params_)\naccuracy = CV_dt.best_score_ *100\nprint(\"Accuracy for our training dataset with tuning is : {:.2f}%\".format(accuracy) )\nprint(classification_report(y_test,CV_dt.best_estimator_.predict(x_test)))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cm=metrics.confusion_matrix(y_test,CV_dt.best_estimator_.predict(x_test))\ndisp=metrics.ConfusionMatrixDisplay(confusion_matrix=cm)\ndisp.plot()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\ngrid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l2\"],'solver':['newton-cg', 'lbfgs']}# l1 lasso l2 ridge\nlogreg=LogisticRegression(random_state=42,max_iter=10000)\nlogreg_cv=GridSearchCV(logreg,grid,cv=5)\nlogreg_cv.fit(x_train_scaled,y_train)\nprint(\"tuned hpyerparameters :(best parameters) \",logreg_cv.best_params_)\nlogregAccuracy = logreg_cv.best_score_ *100\nprint(\"Accuracy for our training dataset with tuning is : {:.2f}%\".format(logregAccuracy) )\nprint(classification_report(y_test,logreg_cv.best_estimator_.predict(x_test_scaled)))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from xgboost import XGBClassifier\nparams = { \n    'n_estimators': [100,200, 500],\n    'learning_rate': [0.1, 0.01, 0.05]\n}\n\nXGB_model = XGBClassifier(seed=42)\nxgbcv=GridSearchCV(estimator=XGB_model,param_grid=params,cv=5)\nxgbcv.fit(x_train, y_train)\n\nprint(xgbcv.best_params_)\naccuracy = xgbcv.best_score_ *100\nprint(\"Accuracy for our training dataset with tuning is : {:.2f}%\".format(accuracy) )\nprint(classification_report(y_test,xgbcv.best_estimator_.predict(x_test)))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from xgboost import XGBClassifier\nXGB_model = XGBClassifier(seed=42,n_estimators=1000,learning_rate=0.05)\nXGB_model.fit(x_train, y_train)\nprint(classification_report(y_test,XGB_model.predict(x_test)))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrfc=RandomForestClassifier(random_state=42)\nparam_grid = { \n    'n_estimators': [100,200, 500],\n    'max_features': [ 'sqrt', 'log2'],\n#     'max_depth' : [4,5,6,7,8],\n    'criterion' :['gini', 'entropy']\n}\nCV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\nCV_rfc.fit(x_train, y_train)\nprint(CV_rfc.best_params_)\naccuracy = CV_rfc.best_score_ *100\nprint(\"Accuracy for our training dataset with tuning is : {:.2f}%\".format(accuracy) )\nprint(classification_report(y_test,CV_rfc.best_estimator_.predict(x_test)))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.svm import SVC\nparam_grid = {'C': [0.1, 1, 10, 100, 1000], \n              'gamma': ['scale','auto'],\n              'kernel': ['rbf','linear']} \n              # ,'linear','sigmoid'\n  \ngrid = GridSearchCV(SVC(random_state=42,class_weight='balanced',), param_grid, refit = True, verbose = 3)\n  \n# fitting the model for grid search\ngrid.fit(x_train_scaled, y_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(grid.best_params_)\naccuracy = grid.best_score_ *100\nprint(\"Accuracy for our training dataset with tuning is : {:.2f}%\".format(accuracy) )\nprint(classification_report(y_test,grid.best_estimator_.predict(x_test_scaled)))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import AdaBoostClassifier\nada=AdaBoostClassifier(random_state=42)\nparams = { \n    'n_estimators': [100,200, 500],\n    'learning_rate': [0.1, 0.01, 0.05]\n}\nadacv=GridSearchCV(estimator=ada,param_grid=params,cv=5)\nadacv.fit(x_train, y_train)\nprint(adacv.best_params_)\naccuracy = adacv.best_score_ *100\nprint(\"Accuracy for our training dataset with tuning is : {:.2f}%\".format(accuracy) )\nprint(classification_report(y_test,adacv.best_estimator_.predict(x_test)))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}